{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "name": "MarkovModel.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NIk6cgTfluF3"
      },
      "source": [
        "#Data scraping and preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2om5xbwl28S"
      },
      "source": [
        "import requests\r\n",
        "from bs4 import BeautifulSoup\r\n",
        "from selenium import webdriver\r\n",
        "import time\r\n",
        "import re"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPjca_i1l7wr"
      },
      "source": [
        "driver = webdriver.Chrome('add your local path to chromewebdriver.exe')\r\n",
        "driver.get('https://www.simplyscripts.com/genre/romance-scripts.html')\r\n",
        "time.sleep(5)\r\n",
        "doc = driver.page_source\r\n",
        "counter = 0\r\n",
        "counter1 = 0\r\n",
        "soup = BeautifulSoup(doc, features='html.parser')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dG8xP9mQl_Ni"
      },
      "source": [
        "for link in soup.find_all('a'):\r\n",
        "    counter += 1\r\n",
        "    lnk = link.get('href')\r\n",
        "    # Check whether the link has a text file, returns a 200 code and is not of a defunct website\r\n",
        "    if(lnk.endswith('txt') and requests.get(lnk).status_code == 200 and 'weeklyscript.com' not in lnk and 'angelfire.com' not in lnk):        \r\n",
        "        counter1 += 1\r\n",
        "        driver.get(lnk)\r\n",
        "        doc1 = driver.page_source\r\n",
        "        soup1 = BeautifulSoup(doc1, features='html.parser')\r\n",
        "        with open('traindata1.txt', 'a') as f:\r\n",
        "            for txt in soup1.find_all('pre'):\r\n",
        "                pattern = r'<pre style=\"word-wrap: break-word; white-space: pre-wrap;\">'\r\n",
        "                txt = re.sub(pattern, '', str(txt))\r\n",
        "                pattern = r'</pre>'\r\n",
        "                txt = re.sub(pattern, '', str(txt))\r\n",
        "                f.write(txt)\r\n",
        "    else:\r\n",
        "        print(str(counter) + \". No text files found!\")\r\n",
        "\r\n",
        "print(\"Total scripts saved:\", counter1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZutKSYKgecB"
      },
      "source": [
        "# Markov Model (some code is courtesy of @ashwinmj)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9FND9fvtgecD"
      },
      "source": [
        "import string\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cOx1useZgecE"
      },
      "source": [
        "# Path of the text file containing the training data\n",
        "data = 'traindata1.txt'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aYrqyZssgecE"
      },
      "source": [
        "#Helper functions\n",
        "def remPunc(sentence):\n",
        "    return sentence.translate(str.maketrans('','', string.punctuation))\n",
        "\n",
        "def dictAdd(dictionary, key, value):\n",
        "    if key not in dictionary:\n",
        "        dictionary[key] = []\n",
        "    dictionary[key].append(value)\n",
        "\n",
        "def probDictAdd(lst):\n",
        "    probs = {}\n",
        "    lstLen = len(lst)\n",
        "    for item in lst:\n",
        "        probs[item] = probs.get(item, 0) + 1\n",
        "    for key, value in probs.items():\n",
        "        probs[key] = value / lstLen\n",
        "    return probs\n",
        "\n",
        "def randomWord(dictionary):\n",
        "    p0 = np.random.random()\n",
        "    cumulative = 0\n",
        "    for key, value in dictionary.items():\n",
        "        cumulative += value\n",
        "        if p0 < cumulative:\n",
        "            return key\n",
        "    assert(False)\n",
        "\n",
        "firstWord = {}\n",
        "secondWord = {}\n",
        "transitions = {}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qf49lwJPgecG"
      },
      "source": [
        "# Trains a Markov model based on the data in data\n",
        "def train():\n",
        "    for line in open(data, encoding='latin-1'):\n",
        "        tokens = remPunc(line.rstrip().lower()).split()\n",
        "        tokensLen = len(tokens)\n",
        "        for i in range(tokensLen):\n",
        "            token = tokens[i]\n",
        "            if i == 0:\n",
        "                firstWord[token] = firstWord.get(token, 0) + 1\n",
        "            else:\n",
        "                prev = tokens[i - 1]\n",
        "                if i == tokensLen - 1:\n",
        "                    dictAdd(transitions, (prev, token), 'END')\n",
        "                if i == 1:\n",
        "                    dictAdd(secondWord, prev, token)\n",
        "                else:\n",
        "                    prevPrev = tokens[i - 2]\n",
        "                    dictAdd(transitions, (prevPrev, prev), token)\n",
        "    \n",
        "    # Normalize the distributions\n",
        "    total = sum(firstWord.values())\n",
        "    for key, value in firstWord.items():\n",
        "        firstWord[key] = value / total\n",
        "        \n",
        "    for prevWord, nextWordLst in secondWord.items():\n",
        "        secondWord[prevWord] = probDictAdd(nextWordLst)\n",
        "        \n",
        "    for pair, nextWordLst in transitions.items():\n",
        "        transitions[pair] = probDictAdd(nextWordLst)\n",
        "    \n",
        "    print('Training successful.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drjuyQLzgecH"
      },
      "source": [
        "numPred = 30\n",
        "\n",
        "# Function to autocomplete sample text\n",
        "def autocomplete():\n",
        "    for i in range(numPred):\n",
        "        sentence = []\n",
        "        # Initial word\n",
        "        word0 = \"she\"\n",
        "        sentence.append(word0)\n",
        "        # Second word\n",
        "        word1 = \"loves\"\n",
        "        sentence.append(word1)\n",
        "        # Subsequent words untill END\n",
        "        while True:\n",
        "            word2 = randomWord(transitions[(word0, word1)])\n",
        "            if word2 == 'END':\n",
        "                break\n",
        "            sentence.append(word2)\n",
        "            word0 = word1\n",
        "            word1 = word2\n",
        "        print(' '.join(sentence))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "biL1EevtgecH"
      },
      "source": [
        "np.random.seed(0)\r\n",
        "train()\r\n",
        "autocomplete()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ozbhab6Wn_uJ"
      },
      "source": [
        "#Recurrent Neural Network Model\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1OKdVbEn8E0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}